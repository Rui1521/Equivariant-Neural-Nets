{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [00:00<00:00, 45.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dilation mats\n",
      "Time_dim 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 40.31it/s]\n",
      " 16%|█▌        | 4/25 [00:00<00:00, 35.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_dim 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 36.77it/s]\n",
      " 12%|█▎        | 4/32 [00:00<00:00, 33.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_dim 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 34.77it/s]\n",
      "  5%|▍         | 3/64 [00:00<00:02, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_dim 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 23.71it/s]\n"
     ]
    }
   ],
   "source": [
    "def dilate_kernel(kernel, dilation):\n",
    "    #print(kernel.shape)\n",
    "    #print(dilation)\n",
    "    if dilation == 0:\n",
    "        return kernel \n",
    "\n",
    "    dilation = torch.tensor(dilation).float()\n",
    "    delta = dilation%1\n",
    "\n",
    "    d_in = torch.ceil(dilation**2).int()\n",
    "    new_in = kernel.shape[2] + (kernel.shape[2]-1)*d_in\n",
    "\n",
    "    d_h = torch.ceil(dilation).int()\n",
    "    new_h = kernel.shape[3] + (kernel.shape[3]-1)*d_h\n",
    "\n",
    "    d_w = torch.ceil(dilation).int()\n",
    "    new_w = kernel.shape[4] + (kernel.shape[4]-1)*d_h\n",
    "\n",
    "    new_kernel = torch.zeros(kernel.shape[0], kernel.shape[1], new_in, new_h, new_w)\n",
    "    new_kernel[:,:,::(d_in+1),::(d_h+1), ::(d_w+1)] = kernel\n",
    "    shrink_factor = 1\n",
    "    # shrink coordinates if the kernel is over dilated.\n",
    "    if delta != 0:\n",
    "        #print(\"    GS - dilation:\",dilation)\n",
    "        new_kernel = F.pad(new_kernel, ((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "\n",
    "        shrink_factor = (new_kernel.shape[-1] - 1 - (kernel.shape[4]-1)*(delta))/(new_kernel.shape[-1] - 1) \n",
    "        grid = torch.meshgrid(torch.linspace(-1, 1, new_in)*(shrink_factor**2), \n",
    "                              torch.linspace(-1, 1, new_h)*shrink_factor, \n",
    "                              torch.linspace(-1, 1, new_w)*shrink_factor)\n",
    "\n",
    "        grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "        new_kernel = F.grid_sample(new_kernel, grid)         \n",
    "        #new_kernel = new_kernel/new_kernel.sum()*kernel.sum()\n",
    "    return new_kernel[:,:,-kernel.shape[2]:]\n",
    "\n",
    "\n",
    "def pre_compute_dilation(time_dims):\n",
    "    dilationdict={}\n",
    "    print(\"Generating Dilation mats\")\n",
    "    for time_dim in time_dims:\n",
    "        print(\"Time_dim\",time_dim)\n",
    "        M = torch.Tensor(time_dim,5,5,time_dim,9,9)  #requires_grad = False \n",
    "        xx = torch.zeros(1,1,time_dim,5,5)\n",
    "        for ti in tqdm.tqdm(range(time_dim)):\n",
    "            for xi in range(5):\n",
    "                for yi in range(5):\n",
    "                    xx[0,0,ti,xi,yi] = 1.0\n",
    "                    M[ti,xi,yi,:,:,:] = dilate_kernel(xx,0.5)\n",
    "                    xx[0,0,ti,xi,yi] = 0.0\n",
    "        dilationdict[time_dim] = M.to(device)\n",
    "    return dilationdict\n",
    "\n",
    "\n",
    "timedims = [16,25,32,64]\n",
    "dilationdict = (pre_compute_dilation(timedims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Conv2d(pl.LightningModule):\n",
    "    def __init__(self, out_channels, in_channels, kernel_size, l = 3, sout = 5, stride = 1, activation = True):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.out_channels= out_channels\n",
    "\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.l = l\n",
    "        self.sout = sout\n",
    "        self.activation = activation\n",
    "        self.kernel_size = kernel_size\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        weight_shape = (out_channels, l, 2, in_channels//2, kernel_size, kernel_size)\n",
    "        self.stdv = math.sqrt(1. / (kernel_size * kernel_size * in_channels * l))\n",
    "        self.weights = nn.Parameter(torch.Tensor(*weight_shape))\n",
    "        self.reset_parameters()\n",
    "        #self.batchnorm = nn.BatchNorm3d(sout)# affine=False\n",
    "        self.stride = stride\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.weights.data.uniform_(-self.stdv, self.stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.fill_(0)\n",
    "            \n",
    "    def shrink_kernel(self, kernel, up_scale):\n",
    "        up_scale = torch.tensor(up_scale).float()\n",
    "        pad_in = (torch.ceil(up_scale**2).int())*((kernel.shape[2]-1)//2)\n",
    "        pad_h = (torch.ceil(up_scale).int())*((kernel.shape[3]-1)//2)\n",
    "        pad_w = (torch.ceil(up_scale).int())*((kernel.shape[4]-1)//2)\n",
    "        padded_kernel = F.pad(kernel, (pad_w, pad_w, pad_h, pad_h, pad_in, pad_in))\n",
    "        delta = up_scale%1\n",
    "        if delta == 0:\n",
    "            shrink_factor = 1\n",
    "        else:\n",
    "            # shrink_factor for coordinates if the kernel is over shrunk.\n",
    "            shrink_factor = (((kernel.shape[4]-1))/(padded_kernel.shape[-1]-1)*(up_scale+1))\n",
    "            # Adjustment to deal with weird filtering on the grid sample function.\n",
    "            shrink_factor = 1.5*(shrink_factor-0.5)**3 + 0.57   \n",
    "\n",
    "        grid = torch.meshgrid(torch.linspace(-1, 1, kernel.shape[2])*(shrink_factor**2),\n",
    "                              torch.linspace(-1, 1, kernel.shape[3])*shrink_factor, \n",
    "                              torch.linspace(-1, 1, kernel.shape[4])*shrink_factor)\n",
    "\n",
    "        grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "        new_kernel = F.grid_sample(padded_kernel, grid.to(device))\n",
    "        if kernel.shape[-1] - 2*up_scale > 0:\n",
    "            new_kernel = new_kernel * (kernel.shape[-1]**2/((kernel.shape[-1] - 2*up_scale)**2 + 0.01))\n",
    "        return new_kernel\n",
    "    \n",
    "    def dilate_kernel(self, kernel, dilation):\n",
    "        #print(kernel.shape)\n",
    "        #print(dilation)\n",
    "        if dilation == 0:\n",
    "            return kernel \n",
    "\n",
    "        dilation = torch.tensor(dilation).float()\n",
    "        delta = dilation%1\n",
    "\n",
    "        d_in = torch.ceil(dilation**2).int()\n",
    "        new_in = kernel.shape[2] + (kernel.shape[2]-1)*d_in\n",
    "\n",
    "        d_h = torch.ceil(dilation).int()\n",
    "        new_h = kernel.shape[3] + (kernel.shape[3]-1)*d_h\n",
    "\n",
    "        d_w = torch.ceil(dilation).int()\n",
    "        new_w = kernel.shape[4] + (kernel.shape[4]-1)*d_h\n",
    "\n",
    "        new_kernel = torch.zeros(kernel.shape[0], kernel.shape[1], new_in, new_h, new_w)\n",
    "        new_kernel[:,:,::(d_in+1),::(d_h+1), ::(d_w+1)] = kernel\n",
    "        shrink_factor = 1\n",
    "        # shrink coordinates if the kernel is over dilated.\n",
    "        if delta != 0:\n",
    "            #print(\"    GS - dilation:\",dilation)\n",
    "            new_kernel = F.pad(new_kernel, ((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "\n",
    "            shrink_factor = (new_kernel.shape[-1] - 1 - (kernel.shape[4]-1)*(delta))/(new_kernel.shape[-1] - 1) \n",
    "            grid = torch.meshgrid(torch.linspace(-1, 1, new_in)*(shrink_factor**2), \n",
    "                                  torch.linspace(-1, 1, new_h)*shrink_factor, \n",
    "                                  torch.linspace(-1, 1, new_w)*shrink_factor)\n",
    "\n",
    "            grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                              grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                              grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "            new_kernel = F.grid_sample(new_kernel, grid)         \n",
    "            #new_kernel = new_kernel/new_kernel.sum()*kernel.sum()\n",
    "        return new_kernel[:,:,-kernel.shape[2]:]\n",
    "    \n",
    "    \n",
    "    def forward(self, xx):\n",
    "        #print(\"weight.shape\",self.weights.shape, \"xx.shape\", xx.shape)\n",
    "        #print(\"self.l\",self.l,\"self.sout\",self.sout)\n",
    "        out = []\n",
    "        #pdb.set_trace()\n",
    "        for s in range(self.sout):\n",
    "            #print(\"s:\",s)\n",
    "            t = np.minimum(s + self.l, self.sout)\n",
    "            inp = xx[:,s:t].reshape(xx.shape[0], -1, xx.shape[-2], xx.shape[-1])\n",
    "            w = self.weights[:,:(t-s),:,:,:].reshape(self.out_channels, 2*(t-s), self.in_channels//2, self.kernel_size, self.kernel_size).to(device)\n",
    "            \n",
    "            #print(\"s:\",s - self.sout//2)\n",
    "            if (s - self.sout//2) < 0:\n",
    "                new_kernel = self.shrink_kernel(w, (self.sout//2 - s)/2).to(device)\n",
    "            elif (s - self.sout//2) == 1:\n",
    "                new_kernel = torch.einsum('cvtxy,txysij->cvsij',w,dilationdict[w.shape[2]]).to(device)\n",
    "                #new_kernel = self.dilate_kernel(w, (s - self.sout//2)/2).to(device)\n",
    "            elif (s - self.sout//2) > 0:\n",
    "                new_kernel = self.dilate_kernel(w, (s - self.sout//2)/2).to(device)\n",
    "            else:\n",
    "                new_kernel = w.to(device)\n",
    "            #print(\"  new_kern_shape:\",new_kernel.shape)\n",
    "    \n",
    "            new_kernel = new_kernel.reshape(self.out_channels, (t-s)*self.in_channels, new_kernel.shape[-2], new_kernel.shape[-1])\n",
    "            conv = F.conv2d(inp, new_kernel, padding = ((new_kernel.shape[-2]-1)//2, (new_kernel.shape[-1]-1)//2))# bias = self.bias,\n",
    "                 \n",
    "            out.append(conv.unsqueeze(1))\n",
    "\n",
    "        out = torch.cat(out, dim = 1) \n",
    "        #print(out.shape)\n",
    "        if self.activation: \n",
    "            #out = self.batchnorm(out)\n",
    "            out = F.leaky_relu(out)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "    \n",
    "class Resblock(pl.LightningModule):\n",
    "    def __init__(self, in_channels, hidden_dim, kernel_size, skip = True):\n",
    "        super(Resblock, self).__init__()\n",
    "        self.layer1 = Conv2d(out_channels = hidden_dim, in_channels = in_channels, kernel_size = kernel_size)\n",
    "     \n",
    "        self.layer2 = Conv2d(out_channels = hidden_dim, in_channels = hidden_dim, kernel_size = kernel_size) \n",
    "        \n",
    "        self.skip = skip\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        if self.skip:\n",
    "            out = self.layer2(out) + x\n",
    "        else:\n",
    "            out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "class Scale_ResNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Scale_ResNet, self).__init__()\n",
    "        \n",
    "        self.input_length = 25\n",
    "        self.output_length = 3\n",
    "        in_channels = self.input_length*2\n",
    "        out_channels = 2 \n",
    "        kernel_size = 5\n",
    "        \n",
    "        self.input_layer = Conv2d(out_channels = 32, in_channels = in_channels, kernel_size = kernel_size)        \n",
    "        layers = [self.input_layer]\n",
    "        layers += [Resblock(32, 32, kernel_size, True), Resblock(32, 32, kernel_size, True)]\n",
    "        layers += [Resblock(32, 64, kernel_size, False), Resblock(64, 64, kernel_size, True)]\n",
    "        layers += [Resblock(64, 128, kernel_size, False), Resblock(128, 128, kernel_size, True)]\n",
    "        layers += [Resblock(128, 128, kernel_size, True), Resblock(128, 128, kernel_size, True)]\n",
    "        layers += [Conv2d(out_channels = 2, in_channels = 128, kernel_size = kernel_size, sout = 1, activation = False)]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, xx):\n",
    "        out = self.model(xx)\n",
    "        out = out.squeeze(1)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), 0.001, betas=(0.9, 0.999), weight_decay=4e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    def loss_fun(self, preds, target):\n",
    "        return torch.nn.MSELoss()(preds, target)  \n",
    "    \n",
    "    def blur_input(self, xx): \n",
    "        out = []\n",
    "        for s in np.linspace(-1, 1, 5):\n",
    "            if s > 0:\n",
    "                blur = gaussain_blur(size = np.ceil(s), sigma = [s**2, s, s], dim  = 3, channels = 1).to(device)\n",
    "                out.append(blur(xx).unsqueeze(1)*(s+1))\n",
    "            elif s<0:\n",
    "                out.append(xx.unsqueeze(1)*(1/(np.abs(s)+1)))\n",
    "            else:\n",
    "                out.append(xx.unsqueeze(1))\n",
    "        out = torch.cat(out, dim = 1)\n",
    "        return out\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        direc = \"../Data/data/\"\n",
    "        train_direc = direc + \"train/sample_\"\n",
    "        valid_direc = direc + \"valid/sample_\"\n",
    "        test_direc = direc + \"test/sample_\"\n",
    "\n",
    "        train_indices = list(range(10,12)) \n",
    "        valid_indices = list(range(60,62)) \n",
    "        test_indices = list(range(80,82))   \n",
    "\n",
    "        self.train_dataset = Dataset(train_indices, self.input_length, 40, self.output_length, train_direc)\n",
    "        self.val_dataset = Dataset(valid_indices, self.input_length, 40, 6, valid_direc)\n",
    "        self.test_dataset = Dataset(test_indices, self.input_length, 40, 10, test_direc) \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(self.train_dataset, batch_size = 2, shuffle = True) \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return data.DataLoader(self.val_dataset, batch_size = 2, shuffle = False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return data.DataLoader(self.test_dataset, batch_size = 2, shuffle = False)\n",
    "\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        xx, yy = train_batch\n",
    "        loss = 0\n",
    "        ims = []\n",
    "        train_rmse = []\n",
    "        for i in range(yy.shape[2]):\n",
    "            blur_xx = self.blur_input(xx)\n",
    "            im = self.forward(blur_xx)\n",
    "            xx = torch.cat([xx[:, :, 1:], im.unsqueeze(2)], 2)\n",
    "            loss += self.loss_fun(im, yy[:,:,i])\n",
    "        train_rmse = round(np.sqrt(loss.item()/yy.shape[2]), 5)\n",
    "        return {'loss': loss, 'train_rmse': train_rmse}\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        xx, yy = val_batch\n",
    "        loss = 0\n",
    "        ims = []\n",
    "        for i in range(yy.shape[2]):\n",
    "            blur_xx = self.blur_input(xx)\n",
    "            im = self.forward(blur_xx)\n",
    "            xx = torch.cat([xx[:, :, 1:], im.unsqueeze(2)], 2)\n",
    "            loss += self.loss_fun(im, yy[:,:,i])\n",
    "            ims.append(im.unsqueeze(2))\n",
    "                \n",
    "        valid_rmse = round(np.sqrt(loss.item()/yy.shape[2]), 5)\n",
    "        ims = torch.cat(ims, axis = 2)\n",
    "        return {'val_loss': valid_rmse, 'preds': ims, \"trues\": yy}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = round(np.mean([x['val_loss'] for x in outputs]), 5)\n",
    "        preds = torch.cat([x['preds'] for x in outputs], dim = 0).cpu().data.numpy()\n",
    "        trues = torch.cat([x['trues'] for x in outputs], dim = 0).cpu().data.numpy()\n",
    "        return {'valid_rmse': avg_loss, 'preds': preds, 'trues': trues}\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        xx, yy = test_batch\n",
    "        loss = 0\n",
    "        ims = []\n",
    "        for i in range(yy.shape[2]):\n",
    "            blur_xx = self.blur_input(xx)\n",
    "            im = self.forward(blur_xx)\n",
    "            xx = torch.cat([xx[:, :, 1:], im.unsqueeze(2)], 2)\n",
    "            loss += self.loss_fun(im, yy[:,:,i])\n",
    "            ims.append(im.unsqueeze(2))\n",
    "                \n",
    "        test_rmse = round(np.sqrt(loss.item()/yy.shape[2]), 5)\n",
    "        ims = torch.cat(ims, axis = 2)\n",
    "        return {'test_loss': test_rmse, 'preds': ims, \"trues\": yy}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = round(np.mean([x['test_loss'] for x in outputs]), 5)\n",
    "        preds = torch.cat([x['preds'] for x in outputs], dim = 0).cpu().data.numpy()\n",
    "        trues = torch.cat([x['trues'] for x in outputs], dim = 0).cpu().data.numpy()\n",
    "        return {'test_rmse': avg_loss, 'preds': preds, 'trues': trues}\n",
    "    \n",
    "   \n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, indices, input_length, mid, output_length, direc):\n",
    "        self.input_length = input_length\n",
    "        self.mid = mid\n",
    "        self.output_length = output_length\n",
    "        self.direc = direc\n",
    "        self.list_IDs = indices\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        x = torch.load(self.direc + str(ID) + \".pt\")[(self.mid-self.input_length):self.mid].transpose(0,1)\n",
    "        y = torch.load(self.direc + str(ID) + \".pt\")[self.mid:(self.mid+self.output_length)].transpose(0,1)\n",
    "        return x.float(), y.float()\n",
    "    \n",
    "    \n",
    "class gaussain_blur(pl.LightningModule):\n",
    "    def __init__(self, size, sigma, dim, channels):\n",
    "        super(gaussain_blur, self).__init__()\n",
    "        self.kernel = self.gaussian_kernel(size, sigma, dim, channels).to(device)\n",
    "\n",
    "    def gaussian_kernel(self, size, sigma, dim, channels):\n",
    "\n",
    "        kernel_size = 2*size + 1\n",
    "        kernel_size = [kernel_size] * dim\n",
    "        kernel = 1\n",
    "        meshgrids = torch.meshgrid([torch.arange(size, dtype=torch.float32) for size in kernel_size])\n",
    "\n",
    "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
    "            mean = (size - 1) / 2\n",
    "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * torch.exp(-((mgrid - mean) / (2 * std)) ** 2)\n",
    "\n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        kernel = kernel / torch.sum(kernel)\n",
    "\n",
    "        # Reshape to depthwise convolutional weight\n",
    "        kernel = kernel.view(1, 1, *kernel.size())\n",
    "        kernel = kernel.repeat(1, channels, 1, 1, 1)\n",
    "\n",
    "        return kernel\n",
    "\n",
    "    def forward(self, xx):\n",
    "        xx = xx.reshape(xx.shape[0]*2, 1, xx.shape[2], xx.shape[3], xx.shape[4])\n",
    "        xx = F.conv3d(xx, self.kernel, padding = (self.kernel.shape[-1]-1)//2)\n",
    "        return xx.reshape(xx.shape[0]//2, 2, xx.shape[2], xx.shape[3], xx.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "##### import torch\n",
    "#from model import Scale_ResNet\n",
    "import pytorch_lightning as pl\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "\n",
    "model = Scale_ResNet()\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=1)\n",
    "trainer.fit(model)\n",
    "\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.rand([32, 3, 2, 25, 5, 5])\n",
    "kernel = torch.rand([32, 2, 16, 5, 5])\n",
    "l = 3 \n",
    "sout = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                batch_size x num_scales x channel_dim x timesteps x x_res x y_res\n",
    "xx = torch.rand([4, 5, 2, 25, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([32, 3, 2, 25, 5, 5]) torch.Size([4, 5, 2, 25, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: tensor(0.5000)\n",
      "tensor(127, dtype=torch.int32)\n",
      "d_in d_h d_w 1 1 1\n",
      "new_kernel torch.Size([32, 2, 127, 9, 9])\n",
      "new new_kernel torch.Size([32, 2, 131, 13, 13])\n",
      "(2, 2, 2, 2, 2, 2)\n",
      "tensor(0.8333)\n",
      "torch.Size([32, 2, 64, 9, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/.local/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dilation = torch.tensor(0.5)\n",
    "kernel = torch.rand([32, 2, 64, 5, 5])\n",
    "\n",
    "dilation = torch.tensor(dilation).float()\n",
    "delta = dilation%1\n",
    "\n",
    "\n",
    "\n",
    "print(\"delta:\",delta)\n",
    "\n",
    "d_in = torch.ceil(dilation**2).int()  ## Fancy way to write 1 ? \n",
    "#print(d_in)\n",
    "new_in = kernel.shape[2] + (kernel.shape[2]-1)*d_in\n",
    "print(new_in)\n",
    "\n",
    "d_h = torch.ceil(dilation).int()\n",
    "new_h = kernel.shape[3] + (kernel.shape[3]-1)*d_h\n",
    "#print(new_h)\n",
    "\n",
    "d_w = torch.ceil(dilation).int()\n",
    "new_w = kernel.shape[4] + (kernel.shape[4]-1)*d_h\n",
    "#print(new_w)\n",
    "\n",
    "new_kernel = torch.zeros(kernel.shape[0], kernel.shape[1], new_in, new_h, new_w)\n",
    "print(\"d_in d_h d_w\",d_in.item(),d_h.item(),d_w.item())\n",
    "print(\"new_kernel\",new_kernel.shape)\n",
    "new_kernel[:,:,::(d_in+1),::(d_h+1), ::(d_w+1)] = kernel\n",
    "shrink_factor = 1\n",
    "# shrink coordinates if the kernel is over dilated.\n",
    "if delta != 0:\n",
    "    new_kernel = F.pad(new_kernel, ((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "    print(\"new new_kernel\",new_kernel.shape)\n",
    "    print(((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "    \n",
    "    shrink_factor = (new_kernel.shape[-1] - 1 - (kernel.shape[4]-1)*(delta))/(new_kernel.shape[-1] - 1)\n",
    "    print(shrink_factor)\n",
    "    \n",
    "    grid = torch.meshgrid(torch.linspace(-1, 1, new_in)*(shrink_factor**2), \n",
    "                          torch.linspace(-1, 1, new_h)*shrink_factor, \n",
    "                          torch.linspace(-1, 1, new_w)*shrink_factor)\n",
    "\n",
    "    grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                      grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                      grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "    new_kernel = F.grid_sample(new_kernel, grid)         \n",
    "    #new_kernel = new_kernel/new_kernel.sum()*kernel.sum()\n",
    "print(new_kernel[:,:,-kernel.shape[2]:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "M5to9 = torch.Tensor(64,5,5,64,9,9)\n",
    "xx = torch.zeros(1,1,64,5,5)\n",
    "for ti in range(64):\n",
    "    for xi in range(5):\n",
    "        for yi in range(5):\n",
    "\n",
    "\n",
    "            xx[0,0,ti,xi,yi] = 1.0\n",
    "\n",
    "            M5to9[ti,xi,yi,:,:,:] = pre_dilate_kernel(xx,0.5)\n",
    "            xx[0,0,ti,xi,yi] = 0.0\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 64, 5, 5])\n",
      "torch.Size([64, 5, 5, 64, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(kernel.shape)\n",
    "print(M5to9.shape)\n",
    "new_kernel = torch.einsum('cvtxy,txysij->cvsij',kernel,M5to9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5, 5, 64, 9, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5to9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_dilate_kernel(kernel, dilation):\n",
    "\n",
    "    dilation = torch.tensor(dilation).float()\n",
    "    delta = dilation%1\n",
    "\n",
    "    #print(\"delta:\",delta)\n",
    "\n",
    "    d_in = torch.ceil(dilation**2).int()  ## Fancy way to write 1 ? \n",
    "    #print(d_in)\n",
    "    new_in = kernel.shape[2] + (kernel.shape[2]-1)*d_in\n",
    "    #print(new_in)\n",
    "\n",
    "    d_h = torch.ceil(dilation).int()\n",
    "    new_h = kernel.shape[3] + (kernel.shape[3]-1)*d_h\n",
    "    #print(new_h)\n",
    "\n",
    "    d_w = torch.ceil(dilation).int()\n",
    "    new_w = kernel.shape[4] + (kernel.shape[4]-1)*d_h\n",
    "    #print(new_w)\n",
    "\n",
    "    new_kernel = torch.zeros(kernel.shape[0], kernel.shape[1], new_in, new_h, new_w)\n",
    "    #print(\"d_in d_h d_w\",d_in.item(),d_h.item(),d_w.item())\n",
    "    #print(\"new_kernel\",new_kernel.shape)\n",
    "    new_kernel[:,:,::(d_in+1),::(d_h+1), ::(d_w+1)] = kernel\n",
    "    shrink_factor = 1\n",
    "    # shrink coordinates if the kernel is over dilated.\n",
    "    if delta != 0:\n",
    "        new_kernel = F.pad(new_kernel, ((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "        #print(\"new new_kernel\",new_kernel.shape)\n",
    "        #print(((kernel.shape[4]-1)//2, (kernel.shape[4]-1)//2)*3)\n",
    "\n",
    "        shrink_factor = (new_kernel.shape[-1] - 1 - (kernel.shape[4]-1)*(delta))/(new_kernel.shape[-1] - 1)\n",
    "        #print(shrink_factor)\n",
    "\n",
    "        grid = torch.meshgrid(torch.linspace(-1, 1, new_in)*(shrink_factor**2), \n",
    "                              torch.linspace(-1, 1, new_h)*shrink_factor, \n",
    "                              torch.linspace(-1, 1, new_w)*shrink_factor)\n",
    "\n",
    "        grid = torch.cat([grid[2].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[1].unsqueeze(0).unsqueeze(-1), \n",
    "                          grid[0].unsqueeze(0).unsqueeze(-1)], dim = -1).repeat(kernel.shape[0],1,1,1,1)\n",
    "\n",
    "        new_kernel = F.grid_sample(new_kernel, grid)         \n",
    "        #new_kernel = new_kernel/new_kernel.sum()*kernel.sum()\n",
    "    return new_kernel[:,:,-kernel.shape[2]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['a']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
